# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


# The configuration file needs to define the sources, 
# the channels and the sinks.
# Sources, channels and sinks are defined per agent, 
# in this case called 'agent'

# This property is used for moving data from /tmp/kafka-flume.log to Kafka

agent.sources = r1
agent.channels = c1
agent.sinks = k1



#/** For sources **/
agent.sources.r1.type = exec
# The channel can be defined as follows.
agent.sources.r1.command=tail -F /tmp/kafka-flume.log

#/* for kafka source */
#DEFAULT_KEY_DESERIALIZER = org.apache.kafka.common.serialization.StringDeserializer;
#DEFAULT_VALUE_DESERIALIZER = org.apache.kafka.common.serialization.ByteArrayDeserializer;
#DEFAULT_AUTO_COMMIT = false;
#agent.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
#agent.sources.r1.kafka.bootstrap.servers;
#agent.sources.r1.kafka.topics;
#agent.sources.r1.kafka.topics.regex;
#agent.sources.r1.batchSize; default as 1000
#agent.sources.r1.batchDurationMillis; default as 1000
#agent.sources.r1.migrateZookeeperOffsets; default as true
#agent.sources.r1.useFlumeEventFormat; default as false
#agent.sources.r1.zookeeperConnect;
#agent.sources.r1.topic;
#agent.sources.r1.groupId; default as flume
#agent.sources.r1.key;
#agent.sources.r1.timestamp;
#agent.sources.r1.partition;
#agent.sources.r1.setTopicHeader; default as true
#agent.sources.r1.topicHeader;  default as topic



#/** For channel **/

#/* memory channel */
agent.channels.c1.type=memory
agent.channels.c1.capacity=10000
agent.channels.c1.transactionCapacity=100



#/** For sink **/
# 注意修改testTopic，testServers， /home/kafka.client.truststore.jks 为自己的实际情况值
agent.sinks.k1.type= org.apache.flume.sink.kafka.KafkaSink
agent.sinks.k1.kafka.topic = [testTopic]
agent.sinks.k1.BatchSize = 5000
agent.sinks.k1.batchDurationMillis = 2000
agent.sinks.k1.kafka.bootstrap.servers = [testServers]
agent.sinks.k1.kafka.producer.security.protocol = SASL_SSL
agent.sinks.k1.kafka.producer.sasl.mechanism = ONS
agent.sinks.k1.kafka.producer.sasl.kerberos.service.name = kafka
agent.sinks.k1.kafka.producer.ssl.truststore.location = /home/kafka.client.truststore.jks
agent.sinks.k1.kafka.producer.ssl.truststore.password = KafkaOnsClient
#/* for kafka sink */
#agent.sinks.k1.type= org.apache.flume.sink.kafka.KafkaSink
#agent.sinks.k1.kafka.topic; default as: default-flume-topic
#agent.sinks.k1.flumeBatchSize; default as 100
#agent.sinks.k1.kafka.bootstrap.servers;
#agent.sinks.k1.key;
#agent.sinks.k1.useFlumeEventFormat; default = false;
#agent.sinks.k1.partitionIdHeader;
#agent.sinks.k1.brokerList;
#agent.sinks.k1.requiredAcks;
#agent.sinks.k1.kafka.producer.acks; default as 1;



# Bind the source and sink to the channel
agent.sources.r1.channels = c1
agent.sinks.k1.channel = c1


