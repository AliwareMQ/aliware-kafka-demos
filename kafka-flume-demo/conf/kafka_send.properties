# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.


# The configuration file needs to define the sources, 
# the channels and the sinks.
# Sources, channels and sinks are defined per agent, 
# in this case called 'agent'

agent.sources = r1
agent.channels = c1
agent.sinks = k1



#/** For sources **/

#/* for kafka source */
#DEFAULT_KEY_DESERIALIZER = org.apache.kafka.common.serialization.StringDeserializer;
#DEFAULT_VALUE_DESERIALIZER = org.apache.kafka.common.serialization.ByteArrayDeserializer;
#DEFAULT_AUTO_COMMIT = false;
#agent.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
#agent.sources.r1.kafka.bootstrap.servers;
#agent.sources.r1.kafka.topics;
#agent.sources.r1.kafka.topics.regex;
#agent.sources.r1.batchSize; default as 1000
#agent.sources.r1.batchDurationMillis; default as 1000
#agent.sources.r1.migrateZookeeperOffsets; default as true
#agent.sources.r1.useFlumeEventFormat; default as false
#agent.sources.r1.zookeeperConnect;
#agent.sources.r1.topic;
#agent.sources.r1.groupId; default as flume
#agent.sources.r1.key;
#agent.sources.r1.timestamp;
#agent.sources.r1.partition;
#agent.sources.r1.setTopicHeader; default as true
#agent.sources.r1.topicHeader;  default as topic

agent.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
agent.sources.r1.batchSize = 5000
agent.sources.r1.batchDurationMillis = 2000
agent.sources.r1.kafka.bootstrap.servers = [yourServers]
agent.sources.r1.kafka.topics = [yourTopics]
agent.sources.r1.kafka.consumer.group.id = CID-XXX
agent.sources.r1.kafka.consumer.security.protocol = SASL_SSL
agent.sources.r1.kafka.consumer.sasl.mechanism = ONS
agent.sources.r1.kafka.consumer.sasl.kerberos.service.name = kafka
agent.sources.r1.kafka.consumer.ssl.truststore.location = /yourPath/kafka.client.truststore.jks
agent.sources.r1.kafka.consumer.ssl.truststore.password = KafkaOnsClient

#/** For channel **/

#/* memory channel */
agent.channels.c1.type=memory
agent.channels.c1.capacity=10000
agent.channels.c1.transactionCapacity=100


#/** For sink **/

#/* for kafka sink */
#agent.sinks.k1.type= org.apache.flume.sink.kafka.KafkaSink
#agent.sinks.k1.kafka.topic; default as: default-flume-topic
#agent.sinks.k1.flumeBatchSize; default as 100
#agent.sinks.k1.kafka.bootstrap.servers;
#agent.sinks.k1.key;
#agent.sinks.k1.useFlumeEventFormat; default = false;
#agent.sinks.k1.partitionIdHeader;
#agent.sinks.k1.brokerList;
#agent.sinks.k1.requiredAcks;
#agent.sinks.k1.kafka.producer.acks; default as 1;

#/* for file_roll sink */
agent.sinks.k1.type = file_roll
agent.sinks.k1.channel = c1
agent.sinks.k1.sink.directory = /tmp/flume_r.log



# Bind the source and sink to the channel
agent.sources.r1.channels = c1
agent.sinks.k1.channel = c1


